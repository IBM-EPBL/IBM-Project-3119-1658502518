{"cells": [{"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install keras==2.2.4\n!pip install tensorflow==2.5.0", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Collecting keras==2.2.4\n  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 312 kB 10.0 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50 kB 7.5 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.7.3)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (3.2.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.20.3)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (5.4.1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.15.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.1.2)\nInstalling collected packages: keras-applications, keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.7.0\n    Uninstalling keras-2.7.0:\n      Successfully uninstalled keras-2.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.7.2 requires keras<2.8,>=2.7.0, but you have keras 2.2.4 which is incompatible.\u001b[0m\nSuccessfully installed keras-2.2.4 keras-applications-1.0.8\nCollecting tensorflow==2.5.0\n  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 454.4 MB 19 kB/s s eta 0:00:01|\u2588\u2588\u2588\u2588\u258d                           | 61.6 MB 41.1 MB/s eta 0:00:10 |\u2588\u2588\u2588\u2588\u258a                           | 67.0 MB 41.1 MB/s eta 0:00:10 |\u2588\u2588\u2588\u2588\u2589                           | 69.0 MB 41.1 MB/s eta 0:00:1055MB 24.3 MB/s eta 0:00:15MB 36.0 MB/s eta 0:00:10MB 36.0 MB/s eta 0:00:10MB 36.0 MB/s eta 0:00:10\ufffd\ufffd\u2588\u2588\u2588\u258e                      | 131.3 MB 36.0 MB/s eta 0:00:09\ufffd\ufffd\u2588\u2588\u2588\u258c                      | 135.6 MB 36.0 MB/s eta 0:00:09\ufffd\ufffd\u2588\u2588\u2588\u258a                      | 138.7 MB 36.0 MB/s eta 0:00:090 MB/s eta 0:00:08\u2588\u2588                    | 168.9 MB 38.0 MB/s eta 0:00:08\u2588\u2588                    | 170.9 MB 38.0 MB/s eta 0:00:08/s eta 0:00:07        | 196.2 MB 38.8 MB/s eta 0:00:07        | 198.5 MB 38.8 MB/s eta 0:00:07 0:00:07/s eta 0:00:06\ufffd\ufffd\u258e               | 230.6 MB 39.8 MB/s eta 0:00:06\ufffd\ufffd\u258d               | 232.2 MB 39.8 MB/s eta 0:00:06\ufffd\ufffd\u258c               | 234.3 MB 39.8 MB/s eta 0:00:06 |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b               | 236.3 MB 39.8 MB/s eta 0:00:06MB/s eta 0:00:05MB/s eta 0:00:05MB/s eta 0:00:05MB/s eta 0:00:05MB/s eta 0:00:05\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 402.5 MB 23.8 MB/s eta 0:00:03\n\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.7.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.3.0)\nCollecting grpcio~=1.34.0\n  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.0 MB 31.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: gast==0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.4.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.9 MB 35.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.2.0)\nCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 462 kB 33.7 MB/s eta 0:00:01\n\u001b[?25hCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.4 MB 30.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.2)\nCollecting keras-nightly~=2.5.0.dev\n  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.2 MB 31.2 MB/s eta 0:00:01\n\u001b[?25hCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.15.0)\nCollecting typing-extensions~=3.7.4\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.6.3)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.19.1)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.37.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.12.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.12.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.0.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.6.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.23.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.26.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (58.0.4)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.4)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.3)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.1)\nInstalling collected packages: numpy, grpcio, typing-extensions, tensorflow-estimator, keras-nightly, h5py, flatbuffers, tensorflow\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.3\n    Uninstalling numpy-1.20.3:\n      Successfully uninstalled numpy-1.20.3\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.42.0\n    Uninstalling grpcio-1.42.0:\n      Successfully uninstalled grpcio-1.42.0\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Uninstalling typing-extensions-4.1.1:\n      Successfully uninstalled typing-extensions-4.1.1\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.7.0\n    Uninstalling tensorflow-estimator-2.7.0:\n      Successfully uninstalled tensorflow-estimator-2.7.0\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.2.1\n    Uninstalling h5py-3.2.1:\n      Successfully uninstalled h5py-3.2.1\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 2.0\n    Uninstalling flatbuffers-2.0:\n      Successfully uninstalled flatbuffers-2.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.7.2\n    Uninstalling tensorflow-2.7.2:\n      Successfully uninstalled tensorflow-2.7.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.5.0 which is incompatible.\npytorch-lightning 1.6.5 requires typing-extensions>=4.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\nautoai-ts-libs 1.1.9 requires tensorflow<2.8,>=2.7.0; python_version >= \"3.9\", but you have tensorflow 2.5.0 which is incompatible.\u001b[0m\nSuccessfully installed flatbuffers-1.12 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='sZmW7ChAxF_z7fqdh9QjWZaoANyi2onbO3YJsULM0GGe',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n\nbucket = 'classificationofecg-donotdelete-pr-pvvx2hiz4wniw3'\nobject_key = 'project.ipynb'\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='sZmW7ChAxF_z7fqdh9QjWZaoANyi2onbO3YJsULM0GGe',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu.cloud-object-storage.appdomain.cloud')\n\nbucket = 'classificationofecg-donotdelete-pr-pvvx2hiz4wniw3'\nobject_key = 'Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image Representation.zip'\n\nstreaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 9, "outputs": []}, {"metadata": {"id": "nroi6VDOLOJD"}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\nfile_paths=unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 10, "outputs": []}, {"metadata": {"id": "8Uf5AlTQLbIG"}, "cell_type": "code", "source": "from  tensorflow.keras.preprocessing.image import ImageDataGenerator", "execution_count": 11, "outputs": []}, {"metadata": {"id": "WZav0aCyLt4N"}, "cell_type": "code", "source": "#image_augmentation", "execution_count": 12, "outputs": []}, {"metadata": {"id": "EhHfarkXL4zg"}, "cell_type": "code", "source": "train_ds=ImageDataGenerator(rescale=1./255,\n                            shear_range=0.2,\n                            zoom_range=0.2,\n                            horizontal_flip=True,\n                            vertical_flip=True)", "execution_count": 13, "outputs": []}, {"metadata": {"id": "xyBdd2KqMKWQ"}, "cell_type": "code", "source": "test_ds=ImageDataGenerator(rescale=1./255)", "execution_count": 14, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "bQmFpN5UMP5h", "outputId": "e1f4601b-6e25-485d-a8a4-8f5b6077e20d"}, "cell_type": "code", "source": "x_train=train_ds.flow_from_directory(r'data/train',\n                                     target_size=(192,128),\n                                     class_mode='categorical',\n                                     batch_size=32)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "Found 15341 images belonging to 6 classes.\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "IiD3XY7KQAqo", "outputId": "ef66afe3-e03a-46ce-d14d-faca714b19d6"}, "cell_type": "code", "source": "x_test=test_ds.flow_from_directory(r'data/test',\n                                   target_size=(192,128),\n                                   class_mode='categorical',\n                                   batch_size=32)", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Found 6825 images belonging to 6 classes.\n", "name": "stdout"}]}, {"metadata": {"id": "NSb3UVORa8bC"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fO9zkXa4cf6X", "outputId": "faf6da68-5c4b-4f33-cbb0-f84ded7677fa"}, "cell_type": "code", "source": "x_train.class_indices", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "{'Left Bundle Branch Block': 0,\n 'Normal': 1,\n 'Premature Atrial Contraction': 2,\n 'Premature Ventricular Contractions': 3,\n 'Right Bundle Branch Block': 4,\n 'Ventricular Fibrillation': 5}"}, "metadata": {}}]}, {"metadata": {"id": "WzBgXl_bclD6"}, "cell_type": "code", "source": "#sprint-2\n#create model", "execution_count": 19, "outputs": []}, {"metadata": {"id": "BRcSAEIqc8ya"}, "cell_type": "code", "source": "from tensorflow.keras.models import Sequential", "execution_count": 20, "outputs": []}, {"metadata": {"id": "sh6BbMr_ehVO"}, "cell_type": "code", "source": "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense", "execution_count": 21, "outputs": []}, {"metadata": {"id": "1-TBskdOe7-D"}, "cell_type": "code", "source": "model=Sequential()", "execution_count": 22, "outputs": []}, {"metadata": {"id": "Ze_IUZiXe-2U"}, "cell_type": "code", "source": "#add layers", "execution_count": 23, "outputs": []}, {"metadata": {"id": "LOjGc2QdfF72"}, "cell_type": "code", "source": "model.add(Convolution2D(32,(3,3),input_shape=(192,128,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Convolution2D(32,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dense(6,activation='softmax'))", "execution_count": 24, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "d-QauEt5kYeo", "outputId": "39442bb4-c492-4dc7-bc75-35710b2be8c6"}, "cell_type": "code", "source": "model.summary()", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 190, 126, 32)      896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 95, 63, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 93, 61, 32)        9248      \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 46, 30, 32)       0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 44160)             0         \n                                                                 \n dense (Dense)               (None, 32)                1413152   \n                                                                 \n dense_1 (Dense)             (None, 6)                 198       \n                                                                 \n=================================================================\nTotal params: 1,423,494\nTrainable params: 1,423,494\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {"id": "fAvDBzZjk-oO"}, "cell_type": "code", "source": "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])", "execution_count": 26, "outputs": []}, {"metadata": {"colab": {"background_save": true, "base_uri": "https://localhost:8080/"}, "id": "L__6DETcKn0T", "outputId": "79694dfc-35de-49ca-fddc-933a22bc3c2b"}, "cell_type": "code", "source": "model.fit_generator(generator=x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))", "execution_count": 27, "outputs": [{"output_type": "stream", "text": "/tmp/wsuser/ipykernel_164/1926459362.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(generator=x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n", "name": "stderr"}, {"output_type": "stream", "text": "Epoch 1/10\n480/480 [==============================] - 327s 679ms/step - loss: 1.5080 - accuracy: 0.4747 - val_loss: 1.5269 - val_accuracy: 0.3193\nEpoch 2/10\n480/480 [==============================] - 326s 679ms/step - loss: 0.7394 - accuracy: 0.7544 - val_loss: 0.7448 - val_accuracy: 0.7364\nEpoch 3/10\n480/480 [==============================] - 323s 672ms/step - loss: 0.3862 - accuracy: 0.8810 - val_loss: 0.8211 - val_accuracy: 0.8113\nEpoch 4/10\n480/480 [==============================] - 323s 673ms/step - loss: 0.3552 - accuracy: 0.8918 - val_loss: 0.7482 - val_accuracy: 0.7848\nEpoch 5/10\n480/480 [==============================] - 323s 673ms/step - loss: 0.3435 - accuracy: 0.8977 - val_loss: 0.8243 - val_accuracy: 0.8275\nEpoch 6/10\n480/480 [==============================] - 322s 670ms/step - loss: 0.3232 - accuracy: 0.9007 - val_loss: 0.7220 - val_accuracy: 0.8116\nEpoch 7/10\n480/480 [==============================] - 331s 689ms/step - loss: 0.3285 - accuracy: 0.9021 - val_loss: 0.6537 - val_accuracy: 0.8305\nEpoch 8/10\n480/480 [==============================] - 327s 681ms/step - loss: 0.3139 - accuracy: 0.9076 - val_loss: 0.7267 - val_accuracy: 0.8475\nEpoch 9/10\n480/480 [==============================] - 322s 671ms/step - loss: 0.3105 - accuracy: 0.9075 - val_loss: 0.6458 - val_accuracy: 0.8457\nEpoch 10/10\n480/480 [==============================] - 324s 674ms/step - loss: 0.2863 - accuracy: 0.9147 - val_loss: 0.8239 - val_accuracy: 0.8375\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "<keras.callbacks.History at 0x7ff31718b910>"}, "metadata": {}}]}, {"metadata": {"id": "oSUkFikKLBdO"}, "cell_type": "code", "source": "\nmodel.save('ECG.h5')\n", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf image-Classification-model_new.tgz ECG.h5", "execution_count": 91, "outputs": [{"output_type": "stream", "text": "ECG.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls -1", "execution_count": 92, "outputs": [{"output_type": "stream", "text": "\u001b[0m\u001b[01;34mdata\u001b[0m/\r\nECG.h5\r\nimage-Classification-model_new.tgz\r\n", "name": "stdout"}]}, {"metadata": {"id": "T6f3CGz1X_41"}, "cell_type": "code", "source": "#testing the model\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image", "execution_count": 31, "outputs": []}, {"metadata": {"id": "NYt1ywV9YEzU"}, "cell_type": "code", "source": "model=load_model(\"ECG.h5\")", "execution_count": 32, "outputs": []}, {"metadata": {"id": "rxF1qdLZYKhU"}, "cell_type": "code", "source": "img1=image.load_img(r'data/test/Premature Ventricular Contractions/VEBfig_13.png')", "execution_count": 33, "outputs": []}, {"metadata": {"id": "qJp7PEsZYOrP"}, "cell_type": "code", "source": "img1", "execution_count": 34, "outputs": [{"output_type": "execute_result", "execution_count": 34, "data": {"text/plain": "<PIL.Image.Image image mode=RGB size=192x128 at 0x7FF317B59D00>", "image/png": "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\n"}, "metadata": {}}]}, {"metadata": {"id": "F8ldjmQgYUs1"}, "cell_type": "code", "source": "img1=img1.resize((128,192))", "execution_count": 35, "outputs": []}, {"metadata": {"id": "l3tmIBZeYV1T"}, "cell_type": "code", "source": "x=image.img_to_array(img1)", "execution_count": 36, "outputs": []}, {"metadata": {"id": "K-Rk0vilYYmi"}, "cell_type": "code", "source": "x", "execution_count": 37, "outputs": [{"output_type": "execute_result", "execution_count": 37, "data": {"text/plain": "array([[[255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.]],\n\n       [[255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.]],\n\n       [[255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.]],\n\n       ...,\n\n       [[255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.]],\n\n       [[255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.]],\n\n       [[255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [255., 255., 255.]]], dtype=float32)"}, "metadata": {}}]}, {"metadata": {"id": "l54h6FsoYhWo"}, "cell_type": "code", "source": "import numpy as np", "execution_count": 38, "outputs": []}, {"metadata": {"id": "hKTxNIp9YkqD"}, "cell_type": "code", "source": "x=np.expand_dims(x,axis=0)", "execution_count": 39, "outputs": []}, {"metadata": {"id": "0gc-F-iXYlsl"}, "cell_type": "code", "source": "y=np.argmax(model.predict(x))", "execution_count": 40, "outputs": []}, {"metadata": {"id": "4LA9PSPtYpUt"}, "cell_type": "code", "source": "y", "execution_count": 41, "outputs": [{"output_type": "execute_result", "execution_count": 41, "data": {"text/plain": "3"}, "metadata": {}}]}, {"metadata": {"id": "1jxVIejKYt6v"}, "cell_type": "code", "source": "index=['Left Bundle Branch Block','Normal','Premature Atrial Contractions','Premature Ventricular Contractions','Right Bundle Branch Block','Ventricular Fibrillation']", "execution_count": 42, "outputs": []}, {"metadata": {"id": "PrZDG_pWYt-T"}, "cell_type": "code", "source": "index[y]", "execution_count": 43, "outputs": [{"output_type": "execute_result", "execution_count": 43, "data": {"text/plain": "'Premature Ventricular Contractions'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,'my_model.tar.gz')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": 47, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow as tf\ntf.__version__", "execution_count": 50, "outputs": [{"output_type": "execute_result", "execution_count": 50, "data": {"text/plain": "'2.7.2'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install keras==2.2.4", "execution_count": 51, "outputs": [{"output_type": "stream", "text": "Collecting keras==2.2.4\n  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 312 kB 21.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: h5py in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (3.2.1)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.7.3)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.15.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.20.3)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.1.2)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (5.4.1)\nCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50 kB 14.6 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: keras-applications, keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.7.0\n    Uninstalling keras-2.7.0:\n      Successfully uninstalled keras-2.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.7.2 requires keras<2.8,>=2.7.0, but you have keras 2.2.4 which is incompatible.\u001b[0m\nSuccessfully installed keras-2.2.4 keras-applications-1.0.8\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#deployment\n!pip install watson-machine-learning--Client", "execution_count": 54, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning--Client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 538 kB 21.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (0.8.9)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (1.26.7)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (4.62.3)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (2.26.0)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (1.18.21)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (1.3.4)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (0.3.3)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (2.11.0)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning--Client) (2022.9.24)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning--Client) (0.5.0)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning--Client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning--Client) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning--Client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning--Client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning--Client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning--Client) (2.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning--Client) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning--Client) (2.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning--Client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning--Client) (1.20.3)\nInstalling collected packages: watson-machine-learning-Client\nSuccessfully installed watson-machine-learning-Client-1.0.391\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials={\n    \"url\":\"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\":\"jODT-AnyGz3AWuG_kZdrQUOBNM5whihNrQnnLZ-h1x3U\"\n}\nclient=APIClient(wml_credentials)", "execution_count": 57, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client\n", "execution_count": 101, "outputs": [{"output_type": "execute_result", "execution_count": 101, "data": {"text/plain": "<ibm_watson_machine_learning.client.APIClient at 0x7ff2f47b28e0>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "def guid_space_name(client,img_class):\n    space=client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name']==ecg_deploy)['metadata']['id'])", "execution_count": 102, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid=guid_space_name(client,'ecg_deploy')\nprint(\"Space UID\"+space_uid)", "execution_count": 103, "outputs": [{"output_type": "error", "ename": "StopIteration", "evalue": "", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/2274498215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspace_uid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mguid_space_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ecg_deploy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Space UID\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mspace_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/tmp/wsuser/ipykernel_164/1606986671.py\u001b[0m in \u001b[0;36mguid_space_name\u001b[0;34m(client, ecg_deploy)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mguid_space_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mecg_deploy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resources'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mecg_deploy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mStopIteration\u001b[0m: "]}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 81, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'space_uid' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/2228809534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'space_uid' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_1.15-py3.6')", "execution_count": 83, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "software_space_uid", "execution_count": 84, "outputs": [{"output_type": "execute_result", "execution_count": 84, "data": {"text/plain": "'2b73a275-7cbf-420b-a912-eae7f436e0bc'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details=client.repository.store_model(model='ECG.h5',meta_props={\n    client.repository.ModelMetaNames.NAME:\"CNN\",\n    client.repository.ModelMetaNames.TYPE:'KERAS_2.2.4',\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid\n})\nmodel_id=client.repository.get_model_uid(model_details)", "execution_count": 89, "outputs": [{"output_type": "stream", "text": "Saving trained model in repository failed. 'ECG.h5' file does not have valid format\n", "name": "stderr"}, {"output_type": "error", "ename": "WMLClientError", "evalue": "Saving trained model in repository failed. 'ECG.h5' file does not have valid format", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/1951148020.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_details=client.repository.store_model(model='ECG.h5',meta_props={\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelMetaNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"CNN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelMetaNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'KERAS_2.2.4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelMetaNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOFTWARE_SPEC_UID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msoftware_space_uid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m })\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ibm_watson_machine_learning/repository.py\u001b[0m in \u001b[0;36mstore_model\u001b[0;34m(self, model, meta_props, training_data, training_target, pipeline, feature_names, label_column_names, subtrainingId, round_number, experiment_metadata)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \"\"\"\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_props\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_props\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_column_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubtrainingId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubtrainingId\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperiment_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdocstring_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'str_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTR_TYPE_NAME\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ibm_watson_machine_learning/models.py\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, model, meta_props, training_data, training_target, pipeline, version, artifactid, feature_names, label_column_names, subtrainingId, round_number, experiment_metadata)\u001b[0m\n\u001b[1;32m   1641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Invalid path: neither file nor directory exists under this path: \\'{}\\'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m                 saved_model = self._publish_from_file(model=model, meta_props=meta_props, training_data=training_data,\n\u001b[0m\u001b[1;32m   1644\u001b[0m                                                       \u001b[0mtraining_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                                                       \u001b[0martifactid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifactid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ibm_watson_machine_learning/models.py\u001b[0m in \u001b[0;36m_publish_from_file\u001b[0;34m(self, model, meta_props, training_data, training_target, ver, artifactid, feature_names, label_column_names)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Saving trained model in repository failed. \\'{}\\' file does not have valid format'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;31m# TODO make this way when all frameworks will be supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mWMLClientError\u001b[0m: Saving trained model in repository failed. 'ECG.h5' file does not have valid format"]}]}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,'my_model.tar.gz')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,'fruit-training.ter.gz')", "execution_count": 82, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'model_id' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/212608471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fruit-training.ter.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'model_id' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}